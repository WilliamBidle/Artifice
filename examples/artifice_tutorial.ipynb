{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1e3e0-2440-4fd0-be13-758a4b65d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from artifice.network import NN\n",
    "from artifice.helper import apply_random_permutation, one_hot_encode, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db144b9d-aba4-4236-b6d2-793c0c00c588",
   "metadata": {},
   "source": [
    "# Example on How to Build a Basic Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ec9bc-543c-4561-9f8e-214fff4994fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_sequence = [1,'relu', 2, 'sigmoid', 3]\n",
    "layer_sequence = [1,'relu', 2, 'sigmoid', 3]\n",
    "loss_function = 'MSE'\n",
    "\n",
    "nn = NN(layer_sequence, loss_function)\n",
    "\n",
    "# Avaliable Class Properties\n",
    "print('current weights:\\n', nn.weights, '\\n')\n",
    "print('current activation functions:\\n', nn.activation_funcs, '\\n')\n",
    "print('current loss function:\\n', nn.loss_func_label, ':', nn.loss_func, '\\n')\n",
    "print('traing error:\\n', nn.training_err, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55788985-57d6-4504-9ffd-1f23f78347c6",
   "metadata": {},
   "source": [
    "# Example of Classification with MNIST Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20391ec-6f05-4160-a3bb-92cc5baf0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For Dataset Usage '''\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from artifice.helper import one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5595f8-8d2c-4881-96ee-9415ce392954",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Training Data Prep ###########################\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = (x_train.astype('float32') / 255.).reshape(len(x_train), len(x_train[0])*len(x_train[0][0]))\n",
    "x_test = (x_test.astype('float32') / 255.).reshape(len(x_test), len(x_test[0])*len(x_test[0][0]))\n",
    "\n",
    "num_data_pts = 1000\n",
    "\n",
    "x_train = x_train[0:num_data_pts]\n",
    "y_train = one_hot_encode(y_train[0:num_data_pts])\n",
    "\n",
    "input_shape = x_train[0].size\n",
    "output_shape = y_train[0].size\n",
    "\n",
    "########################### Testing Data Prep ############################\n",
    "\n",
    "num_test_evals = 1000\n",
    "\n",
    "x_test = x_test[0:num_test_evals]\n",
    "y_test = one_hot_encode(y_test[0:num_test_evals])\n",
    "\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0af97-696a-485b-a11e-e87d42d71eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Build network ##############################\n",
    "\n",
    "# layer_sequence = [input_shape, 'ReLU', 392, 'ReLU', 196, 'ReLU', 98, 'ReLU', 49, 'sigmoid', output_shape]\n",
    "layer_sequence = [input_shape, 'relu', 100, 'sigmoid', output_shape] # initialize the layer sequences and corresponding activations\n",
    "\n",
    "loss_function = 'MSE' # declare the loss function\n",
    "\n",
    "nn = NN(layer_sequence, loss_function) # Build a model \n",
    "\n",
    "################################# Run it ##################################\n",
    "\n",
    "nn.train(x_train, y_train, epochs = 1, batch_size = 5, epsilon = 0.01, visualize = True)\n",
    "\n",
    "################################# Testing ##################################\n",
    "\n",
    "nn.evaluate(x_test)\n",
    "\n",
    "# nn.save_model(out_dir=\"../../temp/saved_models\", filename=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc8c90-12cc-47bb-b765-fc645efeaaf1",
   "metadata": {},
   "source": [
    "# Comparison of Different Loss Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38eb36-c7cb-4b59-8d62-523811be0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Training Data Prep ###########################\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = (x_train.astype('float32') / 255.).reshape(len(x_train), len(x_train[0])*len(x_train[0][0]))\n",
    "x_test = (x_test.astype('float32') / 255.).reshape(len(x_test), len(x_test[0])*len(x_test[0][0]))\n",
    "\n",
    "num_data_pts = 1000\n",
    "\n",
    "x_train = x_train[0:num_data_pts]\n",
    "y_train = One_Hot_Encode(y_train[0:num_data_pts])\n",
    "\n",
    "input_shape = x_train[0].size\n",
    "output_shape = y_train[0].size\n",
    "\n",
    "########################### Testing Data Prep ############################\n",
    "\n",
    "num_test_evals = 1000\n",
    "\n",
    "x_test = x_test[0:num_test_evals]\n",
    "y_test = One_Hot_Encode(y_test[0:num_test_evals])\n",
    "\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45030721-bd19-43a2-98ab-bc47a534dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_sequence = [input_shape, 'ReLU', 392, 'ReLU', 196, 'ReLU', 98, 'ReLU', 49, 'sigmoid', output_shape]\n",
    "layer_sequence = [input_shape, 'ReLU', 100, 'sigmoid', output_shape] # initialize the layer sequences and corresponding activations\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "############################## Build network #############################\n",
    "##########################################################################\n",
    "loss_function = 'MSE'\n",
    "\n",
    "nn1 = NN(layer_sequence, loss_function) # Build model \n",
    "\n",
    "################################# Run it ##################################\n",
    "\n",
    "nn1.train(x_train, y_train, batch_size = 5, epsilon = 0.01, visualize = False)\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "\n",
    "##########################################################################\n",
    "############################## Build network #############################\n",
    "##########################################################################\n",
    "\n",
    "loss_function = 'MAE'\n",
    "\n",
    "nn2 = NN(layer_sequence, loss_function) # Build model \n",
    "\n",
    "################################# Run it ##################################\n",
    "\n",
    "nn2.train(x_train, y_train, batch_size = 5, epsilon = 0.01, visualize = False)\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "\n",
    "##########################################################################\n",
    "############################## Build network #############################\n",
    "##########################################################################\n",
    "\n",
    "loss_function = 'MAPE'\n",
    "\n",
    "nn3 = NN(layer_sequence, loss_function) # Build model \n",
    "\n",
    "################################# Run it ##################################\n",
    "\n",
    "nn3.train(x_train, y_train, batch_size = 5, epsilon = 0.01, visualize = False)\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "\n",
    "##########################################################################\n",
    "############################## Build network #############################\n",
    "##########################################################################\n",
    "\n",
    "loss_function = 'MSLE'\n",
    "\n",
    "nn4 = NN(layer_sequence, loss_function) # Build model \n",
    "\n",
    "################################# Run it ##################################\n",
    "\n",
    "nn4.train(x_train, y_train, batch_size = 5, epsilon = 0.01, visualize = False)\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd0b49-b8a0-46e5-86b8-a8fcaf972153",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize = (16,8))\n",
    "            \n",
    "ax[0][0].plot(nn1.training_err, label = '%s' % str(nn1.loss_func)) # to visualize error over time\n",
    "ax[0][0].set_xlabel('Training Sample', fontsize = 14)\n",
    "ax[0][0].set_ylabel('%s Error' % nn1.loss_func_label, fontsize = 14)\n",
    "ax[0][0].grid(linestyle = '--')\n",
    "ax[0][0].legend(fontsize = 12)\n",
    "\n",
    "ax[0][1].plot(nn2.training_err, label = '%s' % str(nn2.loss_func)) # to visualize error over time\n",
    "ax[0][1].set_xlabel('Training Sample', fontsize = 14)\n",
    "ax[0][1].set_ylabel('%s Error' % nn2.loss_func_label, fontsize = 14)\n",
    "ax[0][1].grid(linestyle = '--')\n",
    "ax[0][1].legend(fontsize = 12)\n",
    "\n",
    "ax[1][0].plot(nn3.training_err, label = '%s' % str(nn3.loss_func)) # to visualize error over time\n",
    "ax[1][0].set_xlabel('Training Sample', fontsize = 14)\n",
    "ax[1][0].set_ylabel('%s Error' % nn3.loss_func_label, fontsize = 14)\n",
    "ax[1][0].grid(linestyle = '--')\n",
    "ax[1][0].legend(fontsize = 12)\n",
    "\n",
    "ax[1][1].plot(nn4.training_err, label = '%s' % str(nn4.loss_func)) # to visualize error over time\n",
    "ax[1][1].set_xlabel('Training Sample', fontsize = 14)\n",
    "ax[1][1].set_ylabel('%s Error' % nn4.loss_func_label, fontsize = 14)\n",
    "ax[1][1].grid(linestyle = '--')\n",
    "ax[1][1].legend(fontsize = 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9477a-ed8f-4f21-ab5c-f209360e464c",
   "metadata": {},
   "source": [
    "# Example of Classification with MNIST (only 2 labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755e439-5e32-4393-b5ca-0b74be6b7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_number = 0\n",
    "second_number = 1\n",
    "\n",
    "################################# Params #################################\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_zeros = y_train == first_number\n",
    "train_ones = y_train == second_number\n",
    "\n",
    "x_train = np.array(list(x_train[train_zeros]) + list(x_train[train_ones]))\n",
    "y_train = np.array(list(y_train[train_zeros]) + list(y_train[train_ones]))\n",
    "\n",
    "x_train = (x_train.astype('float32') / 255.).reshape(len(x_train), len(x_train[0])*len(x_train[0][0]))\n",
    "\n",
    "x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
    "\n",
    "x_train, y_train = x_train[:1000], One_Hot_Encode(y_train[:1000])\n",
    "\n",
    "test_zeros = y_test == first_number\n",
    "test_ones = y_test == second_number\n",
    "\n",
    "x_test = np.array(list(x_test[test_zeros]) + list(x_test[test_ones]))\n",
    "y_test = np.array(list(y_test[test_zeros]) + list(y_test[test_ones]))\n",
    "\n",
    "x_test = (x_test.astype('float32') / 255.).reshape(len(x_test), len(x_test[0])*len(x_test[0][0]))\n",
    "\n",
    "x_test, y_test = unison_shuffled_copies(x_test, y_test)\n",
    "\n",
    "x_test, y_test = x_test[:1000], One_Hot_Encode(y_test[:1000])\n",
    "\n",
    "input_shape = x_train[0].size\n",
    "output_shape = y_train[0].size\n",
    "\n",
    "\n",
    "############################## Build network ##############################\n",
    "\n",
    "# layer_sequence = [input_shape, 'ReLU', 392, 'ReLU', 196, 'ReLU', 98, 'ReLU', 49, 'sigmoid', output_shape]\n",
    "layer_sequence = [input_shape, 'ReLU', 100, 'sigmoid', output_shape]\n",
    "\n",
    "loss_function = 'MSE'\n",
    "# loss_function = 'Binary Cross-Entropy'\n",
    "\n",
    "nn = NN(layer_sequence, loss_function) # Build model \n",
    "\n",
    "################################# Run it ##################################\n",
    "\n",
    "nn.train(x_train, y_train, batch_size = 5, epsilon = 0.1, visualize = True)\n",
    "\n",
    "################################# Testing ##################################\n",
    "\n",
    "nn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40084eaa-a6d9-4b2c-bb9e-cfc599e7221c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb39de19-0868-40a5-8475-b70c5bd9518d",
   "metadata": {},
   "source": [
    "# Compare to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dad32f-1cf8-412c-923d-4289dc88085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f2a7f-493a-4c93-9f58-edf04f8194ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "zeros_train = y_train == 0\n",
    "x_train_zeros, y_train_zeros = list(x_train[zeros_train]), list(y_train[zeros_train])\n",
    "zeros_test = y_test == 0\n",
    "x_test_zeros, y_test_zeros = list(x_test[zeros_test]), list(y_test[zeros_test])\n",
    "\n",
    "ones_train = y_train == 1\n",
    "x_train_ones, y_train_ones = list(x_train[ones_train]), list(y_train[ones_train])\n",
    "ones_test = y_test == 1\n",
    "x_test_ones, y_test_ones = list(x_test[ones_test]), list(y_test[ones_test])\n",
    "\n",
    "\n",
    "x_train, y_train = np.array(x_train_zeros + x_train_ones), np.array(y_train_zeros + y_train_ones)\n",
    "x_test, y_test = np.array(x_test_zeros + x_test_ones), np.array(y_test_zeros + y_test_ones)\n",
    "\n",
    "\n",
    "# shuffle arrays\n",
    "\n",
    "x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
    "x_test, y_test = unison_shuffled_copies(x_test, y_test)\n",
    "\n",
    "x_train = (x_train / 255.)\n",
    "x_test = (x_test / 255.)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63279c3-99c7-4c32-9e29-dc3449fa275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  #tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680832a6-11d0-43b6-8257-8ae8ba9d8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b8e9f-ffd2-475e-9255-e07fc46c6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57296b4d-9b80-4694-bdef-13a4b1c83a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size= 5, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab33783f417e33bc25adfd86bb21951daad33a199843654519bb68b1a101f331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
